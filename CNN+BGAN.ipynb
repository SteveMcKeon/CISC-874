{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Vx205WfWeiqq","RqKM2ngNl5Ik"],"authorship_tag":"ABX9TyPfGOVzAr2QDPtBUM6O6nRM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# High Level Feature Extraction\n","CNN/LSTM Model  \n","Train on original data, 50% malware, 50% benign."],"metadata":{"id":"f_0rtA1Mdeha"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"RWcgHodskRxa","executionInfo":{"status":"ok","timestamp":1670469394150,"user_tz":300,"elapsed":7543,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Conv1D, Flatten, MaxPooling1D,LeakyReLU, MaxPool1D, Dropout, LSTM, Embedding, Dense\n","from keras.optimizers import Adam\n","from keras import optimizers"]},{"cell_type":"code","source":["url12000='https://www.dropbox.com/s/zuk6f9ax1hupb5u/finalshuf12000.csv?dl=1'\n","dataset = pd.read_csv(url12000, sep=';',on_bad_lines='skip', header = None)\n","sort = dataset.sort_values(dataset.columns[-1], ascending = False)\n","malwares = sort.head(6000).head(3000)\n","benigns = (sort.tail(6000))#.head(3000)\n","# benigns_extra = (sort.tail(6000)).tail(3000)\n","dataset = malwares.append(benigns, ignore_index=True)\n","dataset = dataset.sample(frac=1).reset_index(drop=True)\n","dataset = np.array(dataset)\n","X_train,Y_train = np.delete(dataset,-1,axis=1),dataset[:,-1]\n","print('X_train.shape is:',X_train.shape)\n","print('Y_train.shape is:',Y_train.shape)\n","Y_train = Y_train.astype(int)\n","Y_train = pd.get_dummies(Y_train).to_numpy()\n","Y_train[0]"],"metadata":{"id":"1gyDrFmBkU4S","executionInfo":{"status":"ok","timestamp":1670469397147,"user_tz":300,"elapsed":3036,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1359c376-d6e4-4114-8179-6b515add630b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train.shape is: (9000, 308)\n","Y_train.shape is: (9000,)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0, 1], dtype=uint8)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["def create_CNN_model(x_train,y_train):\n","    x_train = x_train.reshape(X_train.shape[0], X_train.shape[1])\n","    x_train = x_train.astype(int)\n","    model = Sequential(name=\"CNN_model\")\n","    model.add(Embedding(input_dim=256, output_dim=64, input_length=X_train.shape[1]))\n","    model.add(Conv1D(filters=128, kernel_size=5, strides = 1, padding='valid', activation='relu'))\n","    model.add(MaxPool1D(pool_size=3))\n","    model.add(Dropout(0.3))\n","    model.add(Conv1D(filters=64, kernel_size=3, strides = 1, padding='valid', activation='relu'))\n","    model.add(MaxPool1D(pool_size=3))\n","    model.add(Dropout(0.3))\n","    model.add(LeakyReLU(alpha=(0.1)))\n","    model.add(Flatten())  # Flatten\n","    model.add(Dense(100, activation='relu'))  # Output Layer\n","    model.add(Dense(2, activation='softmax'))  # Output layer\n","    model.summary()\n","    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=.001), metrics=['accuracy'])\n","    history = model.fit(x_train,y_train,batch_size=80,epochs=50,validation_split=0.2)\n","    return model, history\n","CNN_model, history = create_CNN_model(X_train,Y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"c6Lz0Np0oFl9","executionInfo":{"status":"error","timestamp":1670469404416,"user_tz":300,"elapsed":7304,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}},"outputId":"90ef49c5-4fd8-4113-bc22-e6f8f0f2a176"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"CNN_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 308, 64)           16384     \n","                                                                 \n"," conv1d (Conv1D)             (None, 304, 128)          41088     \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 101, 128)         0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 101, 128)          0         \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 99, 64)            24640     \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 33, 64)           0         \n"," 1D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 33, 64)            0         \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 33, 64)            0         \n","                                                                 \n"," flatten (Flatten)           (None, 2112)              0         \n","                                                                 \n"," dense (Dense)               (None, 100)               211300    \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 202       \n","                                                                 \n","=================================================================\n","Total params: 293,614\n","Trainable params: 293,614\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n"," 1/90 [..............................] - ETA: 5:50 - loss: 0.6969 - accuracy: 0.4250"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f8e6e1a044b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mCNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_CNN_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-f8e6e1a044b2>\u001b[0m in \u001b[0;36mcreate_CNN_model\u001b[0;34m(x_train, y_train)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mCNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_CNN_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'CNN_model/embedding/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 985, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-3-f8e6e1a044b2>\", line 20, in <module>\n      CNN_model, history = create_CNN_model(X_train,Y_train)\n    File \"<ipython-input-3-f8e6e1a044b2>\", line 18, in create_CNN_model\n      history = model.fit(x_train,y_train,batch_size=80,epochs=50,validation_split=0.2)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/core/embedding.py\", line 199, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'CNN_model/embedding/embedding_lookup'\nindices[27,243] = -2147483648 is not in [0, 256)\n\t [[{{node CNN_model/embedding/embedding_lookup}}]] [Op:__inference_train_function_1024]"]}]},{"cell_type":"code","source":["#Removes final classification layer and calls predict to get length 32 feature vectors for the GAN\n","CNN_model.pop()\n","CNN_model.summary()"],"metadata":{"id":"a1ftZLeC-bWD","executionInfo":{"status":"aborted","timestamp":1670469404417,"user_tz":300,"elapsed":12,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use pretrained model to extract 32 high level features for only malware, and pass them to GAN. Also extract features for benign files we will use to oversample beside the generated malware."],"metadata":{"id":"m-uHNq2OdvpX"}},{"cell_type":"code","source":["urlMalware='https://www.dropbox.com/s/701tpt672z5paao/headers328overfit.csv?dl=1' # Only malware\n","dataset = pd.read_csv(urlMalware, sep=';',on_bad_lines='skip', header = None)\n","dataset = dataset.iloc[: , :-21]\n","dataset[len(dataset.columns)] = 1.0\n","dataset = np.array(dataset)\n","X_train,Y_train = np.delete(dataset,-1,axis=1),dataset[:,-1]\n","malware_features = CNN_model.predict(X_train,batch_size=80)\n","malware_features.shape"],"metadata":{"id":"tQ6bircYvDwF","executionInfo":{"status":"aborted","timestamp":1670469404417,"user_tz":300,"elapsed":12,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# benigns_extra = np.array(benigns_extra)\n","# X_train,Y_train = np.delete(benigns_extra,-1,axis=1),benigns_extra[:,-1]\n","# new_benign_features = CNN_model.predict(X_train,batch_size=80)\n","# new_benign_features = np.c_[new_benign_features, Y_train]\n","# np.savetxt(\"new_benigns.csv\", new_benign_features, delimiter=\";\")"],"metadata":{"id":"-pexiC_4MF5q","executionInfo":{"status":"aborted","timestamp":1670469404418,"user_tz":300,"elapsed":13,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Boundary Seeking GAN"],"metadata":{"id":"8RlzzEs7d54c"}},{"cell_type":"code","source":["from __future__ import print_function, division\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D, LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import keras.backend as K\n","\n","import matplotlib.pyplot as plt\n","\n","import sys\n","\n","import numpy as np\n","\n","class BGAN():\n","    def __init__(self):\n","        self.img_shape = 32\n","        self.latent_dim = 10\n","        optimizer = Adam(0.0002, 0.5)\n","        self.discriminator = self.build_discriminator()\n","        loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n","        self.discriminator.compile(loss=loss,optimizer=optimizer,metrics=['accuracy'])\n","        self.generator = self.build_generator()\n","        # The generator takes noise as input and generated samples\n","        z = Input(shape=(self.latent_dim,))\n","        generated_sample = self.generator(z)\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","        # The valid takes generated images as input and determines validity\n","        valid = self.discriminator(generated_sample)\n","        # The combined model  (stacked generator and discriminator)\n","        # Trains the generator to fool the discriminator\n","        self.combined = Model(z, valid)\n","        self.combined.compile(loss=self.boundary_loss, optimizer=optimizer)\n","\n","    def build_generator(self):\n","        model = Sequential(name=\"Generator\")\n","        model.add(Dense(256, input_dim=self.latent_dim))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dropout(0.2))\n","        model.add(Dense(512))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dropout(0.2))\n","        model.add(Dense(1024))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dropout(0.2))\n","        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n","\n","        model.summary()\n","        noise = Input(shape=(self.latent_dim,))\n","        sample = model(noise)\n","        return Model(noise, sample)\n","\n","    def build_discriminator(self):\n","        model = Sequential(name=\"Discriminator\")\n","        model.add(Dense(512, input_dim=32))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.2))\n","        model.add(Dense(256))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.2))\n","        model.add(Dense(128))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.2))\n","        model.add(Dense(64))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(1, activation='sigmoid'))\n","\n","        model.summary()\n","        img = Input(shape=self.img_shape)\n","        validity = model(img)\n","        return Model(img, validity)\n","\n","    def boundary_loss(self, y_true, y_pred):\n","        return 0.5 * K.mean((K.log(y_pred) - K.log(1 - y_pred))**2)\n","\n","    def train(self, X_train, epochs, batch_size=80):\n","        # Adversarial ground truths\n","        valid = np.full((batch_size, 1), 0.9)\n","        fake = np.zeros((batch_size, 1))\n","        for epoch in range(epochs):\n","            # ---------------------\n","            #  Train Discriminator\n","            # ---------------------\n","            idx = np.random.randint(0, X_train.shape[0], batch_size)\n","            imgs = X_train[idx]\n","\n","            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","            gen_imgs = self.generator.predict(noise)\n","            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n","            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","            g_loss = self.combined.train_on_batch(noise, valid)\n","            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","\n","    def predict(self, samples, batch_size=80):\n","        noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","        for i in range(samples-1):\n","            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","            gen_imgs = np.append(gen_imgs, self.generator.predict(noise), axis=0)\n","            print(\"%d/%d\" % (i+2, samples))\n","        return gen_imgs"],"metadata":{"id":"KoktrX9avzCB","executionInfo":{"status":"aborted","timestamp":1670469404418,"user_tz":300,"elapsed":13,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bgan = BGAN()\n","bgan.train(malware_features, epochs=120, batch_size=80)\n","fake_malware_samples = bgan.predict(75,  batch_size=80) #75 * 80 new samples = 6000"],"metadata":{"id":"14AkFsclyZKi","executionInfo":{"status":"aborted","timestamp":1670469404419,"user_tz":300,"elapsed":14,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fake_malware_samples.shape"],"metadata":{"id":"DQK2qf8u5NLg","executionInfo":{"status":"aborted","timestamp":1670469404419,"user_tz":300,"elapsed":14,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(fake_malware_samples[0])\n","print(malware_features[0])"],"metadata":{"id":"Yi1kgMfP5rd1","executionInfo":{"status":"aborted","timestamp":1670469404420,"user_tz":300,"elapsed":18807,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fake_malware_samples = np.c_[fake_malware_samples, np.ones(fake_malware_samples.shape[0])]\n","fake_malware_samples.shape"],"metadata":{"id":"aHnDY9uzgiAA","executionInfo":{"status":"aborted","timestamp":1670469404421,"user_tz":300,"elapsed":18800,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.savetxt(\"fake_malware_samples.csv\", fake_malware_samples, delimiter=\";\")"],"metadata":{"id":"DeGxaJiHAynU","executionInfo":{"status":"aborted","timestamp":1670469404421,"user_tz":300,"elapsed":18791,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Processing\n","Get new unique 3000 benign samples to oversample the benign files as well.  \n","Make sure they aren't present in the original 6000 dataset."],"metadata":{"id":"VhOdxk7D0akR"}},{"cell_type":"code","source":["# url12000='https://www.dropbox.com/s/wjxpmvduekwqr5i/dataset12000.csv?dl=1'\n","# dataset = pd.read_csv(url12000, sep=';',on_bad_lines='skip', header = None)\n","# dataset2 = pd.read_csv(url6000, sep=';',on_bad_lines='skip', header = None)\n","# dataset = dataset.drop(dataset[dataset.iloc[:,-1] == 0].index)\n","# dataset2.info()"],"metadata":{"id":"S9G8rYsF2qGX","executionInfo":{"status":"aborted","timestamp":1670469404422,"user_tz":300,"elapsed":18785,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# combined = dataset.merge(dataset2, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']\n","# combined = (combined.drop(['_merge'], axis=1)).head(3000)\n","# combined.info()"],"metadata":{"id":"aNgVYBPcOxZ4","executionInfo":{"status":"aborted","timestamp":1670469404582,"user_tz":300,"elapsed":2,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# new_benign = np.array(combined)\n","# X_train,Y_train = np.delete(new_benign,-1,axis=1),new_benign[:,-1]\n","# new_benign_features = CNN_model.predict(X_train,batch_size=80)\n","# new_benign_features.shape"],"metadata":{"id":"3oL2SYP3QKPf","executionInfo":{"status":"aborted","timestamp":1670469404583,"user_tz":300,"elapsed":2,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# new_benign_features = np.c_[new_benign_features, np.zeros(new_benign_features.shape[0])]"],"metadata":{"id":"xXQ8eBfugNK3","executionInfo":{"status":"aborted","timestamp":1670469404584,"user_tz":300,"elapsed":18926,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Convert original 6000 dataset to extracted features. \n","Will classify them alone, then oversample with the new_samples and new_benign for comparison."],"metadata":{"id":"_Q-R6U5ISHqt"}},{"cell_type":"code","source":["# dataset = pd.read_csv(url12000, sep=';',on_bad_lines='skip', header = None)\n","# dataset = np.array(dataset)\n","dataset = malwares.append(benigns, ignore_index=True)\n","dataset = dataset.sample(frac=1).reset_index(drop=True)\n","dataset = np.array(dataset)\n","X_train,Y_train = np.delete(dataset,-1,axis=1),dataset[:,-1]\n","orig_data_features = CNN_model.predict(X_train,batch_size=80)\n","orig_data_features.shape"],"metadata":{"id":"jx7ynBPGSE3R","executionInfo":{"status":"aborted","timestamp":1670469404585,"user_tz":300,"elapsed":18920,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Add back label\n","orig_data_features = np.c_[orig_data_features, Y_train]"],"metadata":{"id":"_AyEzVVqU2p_","executionInfo":{"status":"aborted","timestamp":1670469404585,"user_tz":300,"elapsed":18911,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.savetxt(\"orig_dataset.csv\", orig_data_features, delimiter=\";\")"],"metadata":{"id":"AnJWkUarSb3a","executionInfo":{"status":"aborted","timestamp":1670469404586,"user_tz":300,"elapsed":18905,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Classification model"],"metadata":{"id":"B6tASO02Twb9"}},{"cell_type":"markdown","source":["### Training\n","With original dataset"],"metadata":{"id":"Vx205WfWeiqq"}},{"cell_type":"code","source":["from keras.layers import *\n","from keras.models import *\n","from keras import backend as K\n","# Add attention layer to the deep learning network\n","class attention(Layer):\n","    def __init__(self,return_sequences=True,**kwargs):\n","      self.return_sequences = return_sequences\n","      super(attention,self).__init__(**kwargs)\n"," \n","    def build(self,input_shape):\n","        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n","                               initializer='random_normal', trainable=True)\n","        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n","                               initializer='zeros', trainable=True)        \n","        #super(attention, self).build(input_shape)\n"," \n","    def call(self,x):\n","        # Alignment scores. Pass them through tanh function\n","        e = K.tanh(K.dot(x,self.W)+self.b)\n","        # Remove dimension of size 1\n","        e = K.squeeze(e, axis=-1)   \n","        # Compute the weights\n","        alpha = K.softmax(e)\n","        # Reshape to tensorFlow format\n","        alpha = K.expand_dims(alpha, axis=-1)\n","        # Compute the context vector\n","        context = x * alpha\n","        context = K.sum(context, axis=1)\n","        return context"],"metadata":{"id":"x-YDUe01Ws7K","executionInfo":{"status":"aborted","timestamp":1670469404586,"user_tz":300,"elapsed":18898,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = pd.read_csv('orig_dataset.csv', sep=';',on_bad_lines='skip', header = None)\n","dataset = np.array(dataset)\n","features,labels = np.delete(dataset,-1,axis=1),dataset[:,-1]\n","X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.60, shuffle=True)\n","Y_train = pd.get_dummies(Y_train).to_numpy()\n","Y_test = pd.get_dummies(Y_test).to_numpy()\n","Y_train = Y_train.astype(int)\n","Y_test = Y_test.astype(int)\n","X_train.shape"],"metadata":{"id":"Wu2x_WMxcMqU","executionInfo":{"status":"aborted","timestamp":1670469404586,"user_tz":300,"elapsed":18891,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(2, X_train.shape[1])"],"metadata":{"id":"68KcapyiJgZH","executionInfo":{"status":"aborted","timestamp":1670469404587,"user_tz":300,"elapsed":18883,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_classification_model(x_train,y_train, batch_size = 80):\n","    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n","    model = Sequential()\n","    model.add(Conv1D(filters=128, kernel_size=5, strides = 1, padding='valid', activation='relu', input_shape=(x_train.shape[1], 1)))\n","    model.add(MaxPool1D(pool_size=3))\n","    model.add(Dropout(0.3))\n","    model.add(Conv1D(filters=64, kernel_size=3, strides = 1, padding='valid', activation='relu'))\n","    model.add(MaxPool1D(pool_size=3))\n","    model.add(Dropout(0.3))\n","    model.add(Bidirectional(LSTM(256, activation='tanh', return_sequences=True,dropout=0.2)))\n","    model.add(attention(return_sequences=True))\n","    model.add(Flatten())  # Flatten\n","    model.add(Dense(100, activation='relu'))  # F6\n","    model.add(Dense(2, activation='softmax'))  # Output layer\n","    model.summary()\n","    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=.001), metrics=['accuracy'])\n","    history = model.fit(x_train,y_train,batch_size=batch_size,epochs=50,validation_split=0.2)\n","    return model, history\n","classification_model, train_result = create_classification_model(X_train,Y_train)"],"metadata":{"id":"fsWQY28yTT61","executionInfo":{"status":"aborted","timestamp":1670469404587,"user_tz":300,"elapsed":18875,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["With oversampling. "],"metadata":{"id":"RxhwL_CwdViw"}},{"cell_type":"code","source":["dataset = pd.read_csv('orig_dataset.csv', sep=';',on_bad_lines='skip', header = None)\n","dataset2 = pd.read_csv('fake_malware_samples.csv', sep=';',on_bad_lines='skip', header = None)\n","# dataset3 = pd.read_csv('new_benigns.csv', sep=';',on_bad_lines='skip', header = None)\n","print(dataset.shape)\n","print(dataset2.shape)\n","# print(dataset3.shape)"],"metadata":{"id":"OXmCXNKZXTYp","executionInfo":{"status":"aborted","timestamp":1670469404588,"user_tz":300,"elapsed":18867,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# frames = [dataset, dataset2.sample(1500)] \n","# frames = [dataset, dataset2.sample(3000)]\n","frames = [dataset, dataset2.sample(3000)] #, dataset3] # Biggest oversample of malware works the best\n","combined_data = pd.concat(frames)\n","combined_data = combined_data.sample(frac=1).reset_index(drop=True)\n","combined_data.shape"],"metadata":{"id":"BdObQAtYgC5I","executionInfo":{"status":"aborted","timestamp":1670469404588,"user_tz":300,"elapsed":18859,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_data = np.array(combined_data)\n","features, labels = np.delete(combined_data,-1,axis=1),combined_data[:,-1]\n","X_train2, X_test2, Y_train2, Y_test2 = train_test_split(features, labels, test_size=0.60, shuffle=True)\n","Y_train2 = pd.get_dummies(Y_train2).to_numpy()\n","Y_test2 = pd.get_dummies(Y_test2).to_numpy()\n","Y_train2 = Y_train2.astype(int)\n","Y_test2 = Y_test2.astype(int)\n","X_train2.shape"],"metadata":{"id":"2PrlO_eCh0WD","executionInfo":{"status":"aborted","timestamp":1670469404745,"user_tz":300,"elapsed":19007,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classification_model2, train_result2 = create_classification_model(X_train2,Y_train2)"],"metadata":{"id":"UMIrPgFzj5kr","executionInfo":{"status":"aborted","timestamp":1670469404747,"user_tz":300,"elapsed":18998,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_training_summary(history):\n","  #Plotting the training and validationaccuracy\n","  plt.figure(figsize = (8,8))\n","  plt.plot(history.history['accuracy'], color = 'blue', label = 'train')\n","  plt.plot(history.history['val_accuracy'], color = 'red', label = 'val')\n","  plt.legend()\n","  plt.title('Accuracy')\n","  plt.show()\n","  \n","  #Plotting the training and validation Loss\n","  plt.figure(figsize = (8,8))\n","  plt.plot(history.history['loss'], color = 'blue', label = 'train')\n","  plt.plot(history.history['val_loss'], color = 'red', label = 'val')\n","  plt.legend()\n","  plt.title('Loss')\n","  plt.show()\n","\n","# Plotting the training and validation loss and accuracy\n","plot_training_summary(train_result)\n","plot_training_summary(train_result2)"],"metadata":{"id":"pnrK6pk7lCYY","executionInfo":{"status":"aborted","timestamp":1670469404748,"user_tz":300,"elapsed":18990,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Original accuracy:\", train_result.history['accuracy'][-1])\n","print(f\"Original validation accuracy:\", train_result.history['val_accuracy'][-1])\n","print(f\"Oversampled accuracy:\", train_result2.history['accuracy'][-1])\n","print(f\"Oversampled validation accuracy:\", train_result2.history['val_accuracy'][-1])"],"metadata":{"id":"QEgrNeicwN9K","executionInfo":{"status":"aborted","timestamp":1670469404750,"user_tz":300,"elapsed":18983,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Testing"],"metadata":{"id":"RqKM2ngNl5Ik"}},{"cell_type":"code","source":["# evaluating the model\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","def model_eval(model, test_x, test_y, title):\n","  loss,accuracy=model.evaluate(test_x, test_y, verbose=2)\n","  print('Accuracy of the model is: ', accuracy*100)\n","  predicted_y=model.predict(test_x)\n","  predicted_y=np.argmax(predicted_y,axis=1)\n","  predicted_y=np.asarray(predicted_y)\n","  test_y=np.argmax(test_y,axis=1)\n","\n","  #Plotting Confusion Matrix\n","  conf_matrix = confusion_matrix(test_y, predicted_y)\n","  ax = plt.subplot()\n","  sns.heatmap(conf_matrix, linewidths = 0.1, cmap = 'Blues', linecolor = 'gray', fmt = '.1f', annot = True, ax=ax)\n","  ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","  ax.set_title('Confusion Matrix\\n' + title); \n","  ax.xaxis.set_ticklabels(['Benign', 'Malware']); \n","  ax.yaxis.set_ticklabels(['Benign', 'Malware']);\n","  plt.figure(figsize=(8,6))\n","  return accuracy, conf_matrix"],"metadata":{"id":"itjIEAInln-o","executionInfo":{"status":"aborted","timestamp":1670469404753,"user_tz":300,"elapsed":18977,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","X_test2 = X_test2.reshape(X_test2.shape[0], X_test2.shape[1], 1)\n","accuracy_1, conf_matrix1 = model_eval(classification_model,X_test,Y_test, 'Model-6')\n","accuracy_1, conf_matrix1 = model_eval(classification_model,X_test,Y_test, 'Model-6')\n","accuracy_2, conf_matrix2 = model_eval(classification_model2,X_test2,Y_test2, 'Model-6 Oversampled')\n","\n","import matplotlib.pyplot as plt\n","fig = plt.figure()\n","ax = fig.add_axes([0,0,1,1])\n","langs = ['Without Oversampling', 'With Oversampling']\n","val_acc = [accuracy_1*100, accuracy_2*100]\n","pps = ax.bar(langs,val_acc)\n","for p in pps:\n","   height = p.get_height()\n","   ax.annotate('{:.3f}%'.format(height), xy=(p.get_x() + p.get_width() / 2, height), xytext=(0, -20), textcoords=\"offset points\", ha='center', va='bottom')\n","plt.ylim(98,100)\n","plt.show()"],"metadata":{"id":"WqBvXFwzl-Ah","executionInfo":{"status":"aborted","timestamp":1670469404754,"user_tz":300,"elapsed":18970,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Original test accuracy:\", accuracy_1)\n","print(f\"Oversampled test accuracy:\", accuracy_2)"],"metadata":{"id":"S3FFxd2_mig9","executionInfo":{"status":"aborted","timestamp":1670469404755,"user_tz":300,"elapsed":18963,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TN1, FP1, FN1, TP1 = conf_matrix1[0][0], conf_matrix1[0][1], conf_matrix1[1][0], conf_matrix1[1][1]\n","TN2, FP2, FN2, TP2 = conf_matrix2[0][0], conf_matrix2[0][1], conf_matrix2[1][0], conf_matrix2[1][1]\n","precision1, precision2 = (TP1/(TP1+FP1))*100, (TP2/(TP2+FP2))*100\n","recall1, recall2 = (TP1/(TP1+FN1))*100, (TP2/(TP2+FN2))*100"],"metadata":{"id":"UFNud_mTW945","executionInfo":{"status":"aborted","timestamp":1670469404756,"user_tz":300,"elapsed":18956,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_1_acc, model_2_acc, model_3_acc, model_1_pre, model_2_pre, model_3_pre, model_1_rec, model_2_rec, model_3_rec = (99.03333187103271,\n"," 99.13333058357239,\n"," 99.23333525657654,\n"," 98.40213049267643,\n"," 98.59906604402934,\n"," 99.32432432432432,\n"," 99.66284558327713,\n"," 99.66284558327713,\n"," 99.12339851652057)"],"metadata":{"id":"sXwECaR_tFUQ","executionInfo":{"status":"aborted","timestamp":1670469404757,"user_tz":300,"elapsed":18950,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","fig = plt.figure()\n","ax = fig.add_axes([0,0,1,1])\n","langs = ['Model-1','Model-2', 'Model-3', 'Model-6', 'Model-6\\nOversampled']\n","test_acc = [model_1_acc, model_2_acc, model_3_acc, accuracy_1*100, accuracy_2*100]\n","bar=ax.bar(langs,test_acc)\n","for p in bar:\n","   height = p.get_height()\n","   ax.annotate('{:.3f}%'.format(height),\n","      xy=(p.get_x() + p.get_width() / 2, height),\n","      xytext=(0, -20), # 3 points vertical offset\n","      textcoords=\"offset points\",\n","      ha='center', va='bottom')\n","bar[0].set_color('r')\n","bar[1].set_color('g')\n","bar[3].set_color('c')\n","bar[4].set_color('m')\n","plt.ylim(98,100)\n","plt.title('Test Accuracy')\n","plt.show()\n","\n","fig = plt.figure()\n","ax = fig.add_axes([0,0,1,1])\n","langs = ['Model-1','Model-2', 'Model-3', 'Model-6', 'Model-6\\nOversampled']\n","test_pre = [model_1_pre, model_2_pre, model_3_pre, precision1, precision2]\n","bar=ax.bar(langs,test_pre)\n","for p in bar:\n","   height = p.get_height()\n","   ax.annotate('{:.3f}%'.format(height),\n","      xy=(p.get_x() + p.get_width() / 2, height),\n","      xytext=(0, -20),\n","      textcoords=\"offset points\",\n","      ha='center', va='bottom')\n","bar[0].set_color('r')\n","bar[1].set_color('g')\n","bar[3].set_color('c')\n","bar[4].set_color('m')\n","plt.ylim(98,100)\n","plt.title('Precision')\n","plt.show()\n","\n","fig = plt.figure()\n","ax = fig.add_axes([0,0,1,1])\n","langs = ['Model-1','Model-2', 'Model-3', 'Model-6', 'Model-6\\nOversampled']\n","test_rec = [model_1_rec, model_2_rec, model_3_rec, recall1, recall2]\n","bar=ax.bar(langs,test_rec)\n","for p in bar:\n","   height = p.get_height()\n","   ax.annotate('{:.3f}%'.format(height),\n","      xy=(p.get_x() + p.get_width() / 2, height),\n","      xytext=(0, -20),\n","      textcoords=\"offset points\",\n","      ha='center', va='bottom')\n","bar[0].set_color('r')\n","bar[1].set_color('g')\n","bar[3].set_color('c')\n","bar[4].set_color('m')\n","plt.ylim(98,100)\n","plt.title('Recall')\n","plt.show()\n","\n","fig = plt.figure()\n","ax = fig.add_axes([0,0,1,1])\n","langs = ['Model-1','Model-2', 'Model-3', 'Model-6', 'Model-6\\nOversampled']\n","test_F1 = [2*(model_1_pre*model_1_rec)/(model_1_pre+model_1_rec), 2*(model_2_pre*model_2_rec)/(model_2_pre+model_2_rec), 2*(model_3_pre*model_3_rec)/(model_3_pre+model_3_rec), 2*(precision1*recall1)/(precision1+recall1), 2*(precision2*recall2)/(precision2+recall2)]\n","bar=ax.bar(langs,test_F1)\n","for p in bar:\n","   height = p.get_height()\n","   ax.annotate('{:.3f}%'.format(height),\n","      xy=(p.get_x() + p.get_width() / 2, height),\n","      xytext=(0, -20),\n","      textcoords=\"offset points\",\n","      ha='center', va='bottom')\n","bar[0].set_color('r')\n","bar[1].set_color('g')\n","bar[3].set_color('c')\n","bar[4].set_color('m')\n","plt.ylim(98,100)\n","plt.title('F1 Score')\n","plt.show()"],"metadata":{"id":"jyjn6J8oKhKG","executionInfo":{"status":"aborted","timestamp":1670469404758,"user_tz":300,"elapsed":18943,"user":{"displayName":"Stephen McKeon","userId":"06569707702911140027"}}},"execution_count":null,"outputs":[]}]}